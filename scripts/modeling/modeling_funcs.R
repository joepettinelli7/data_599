# https://topepo.github.io/caret/recursive-feature-elimination.html 

library(plyr)
library(dplyr)
library(caret)
library(randomForest)
library(pROC)
library(kernlab)
library(e1071)
setwd(file.path(path.expand("~/Desktop"), "data_599"))
source('scripts/plotting.R')
source('scripts/constants.R')

### common functions for both randomForests and SVMs ###
fivestats_summary <- function(data, lev=NULL, model=NULL, plot_roc=FALSE) {
  # twoClassSummary computes sensitivity, specificity, ROC
  # defaultSummary computes accuracy, kappa
  #
  # data: A data frame with columns pred, normal, nsclc, obs, Variables.
  #       Columns normal and nsclc have class probabilities.
  #       The rows represent the held-back samples.
  # lev: A character vector of factor levels (normal and nsclc)
  # model: A character string for the model name
  # plot_roc: Whether to plot ROC.
  #
  # Returns named vector of numeric variables (the 5 performance metrics)
  # for predictions of a single subset size
  pos_class <- levels(data$obs)[2]
  neg_class <- levels(data$obs)[1]
  
  tpr <- function(df, threshold) {
    sum(df[, pos_class] >= threshold & df$obs == pos_class) /
      sum(df$obs == pos_class)
  }
  
  fpr <- function(df, threshold) {
    sum(df[, pos_class] >= threshold & df$obs == neg_class) / 
      sum(df$obs == neg_class)
  }
  
  computeROC <- function(df, thresholds){
    roc <- data.frame(threshold = thresholds,
                      tpr = sapply(thresholds, function(x) tpr(df, x)),
                      fpr = sapply(thresholds, function(x) fpr(df, x)))
    return(roc)
  }

  computeAUC <- function(roc_df) {
    x <- roc_df$fpr
    y <- roc_df$tpr
    auc <- sum(diff(x) * (head(y, -1) + tail(y, -1)) / 2)
    return(auc)
  }
  thresholds <- seq(1, 0, length.out = 1000)
  roc_df <- computeROC(data, thresholds)
  if (plot_roc) {
    print(plot_roc(roc_df))
    print(plot_misclass(data, thresholds, pos_class, neg_class))
  }
  auc_roc <- computeAUC(roc_df)
  sens <- tpr(data, .5)
  spec <- 1 - fpr(data, .5)
  out <- c("ROC" = auc_roc,
           defaultSummary(data),
           "Sens" = sens,
           "Spec" = spec)
  return(out)
}

rfe_selectSize <- function (x, metric, maximize) {
  # x: A matrix with columns for the performance metrics and the number of
  #    variables. Each row corresponds to an rfe subset size.
  # metric: A character string of the performance measure to optimize (ROC)
  # maximize: Whether this metric should be maximized
  #
  # Returns an integer corresponding to the optimal subset size using the
  # one standard error method
  stopifnot(metric == "ROC" & maximize)
  row_idx <- which.max(x[, metric])
  orig_size <- x$Variables[row_idx]
  message('Max ROC-AUC is at subset size ', orig_size)
  # If size is small, don't do one standard error method
  if (orig_size >= ONE_SE_THRESH) {
    row_idx <- oneSE(x, metric, NUM_RFEs, maximize)
  }
  select_size <- x[row_idx, "Variables"]
  message('Selected subset size ', select_size)
  return(select_size)
}

rfe_selectVar <- function(y, best_size) {
  # Needs to be custom when reranking used at each iteration.
  # y: a list of variables importance for each resampling iteration
  #    and each subset size (generated by the user-defined rank function).
  #    Additional columns Variables and Resample are added in which Variables
  #    contains the number of variables and Resample is the resample iteration.
  # size: the integer returned by the selectSize function.
  #
  # Returns a character string of predictor names (of length size) in
  # descending order of importance
  #
  # Only keep rows with best size
  y <- dplyr::filter(y, Variables == best_size)
  # rank metric is MeanDecreaseAccuracy during rf and change in cost function
  # for nonlinear svm
  y <- dplyr::select(y, rank_metric, var)
  # Make groups by variable name (gene name)
  y <- dplyr::group_by(y, var)
  # Get count of each variable (gene name)
  y <- dplyr::summarise(y, count = length(var))
  # Sort in descending order of variable frequency
  y <- dplyr::arrange(y, desc(count))
  # Get top size number of variables
  return(as.character(y$var[1:best_size]))
}

### RF specific ###
rf_pred <- function (object, x) {
  # object: The model generated by the fit function
  # x: The current set of predictor set for the held-back samples
  #
  # Returns a data frame with columns pred, normal, nsclc with rows
  # being the held-back samples (~70 of them in our data set). The pred
  # column contains the predictions normal or nsclc and the normal and nsclc
  # columns contains the class probabilities.
  tmp <- predict(object, x)
  if (is.factor(object$y)) {
    out <- cbind(data.frame(pred = tmp),
                 as.data.frame(predict(object, x, type = "prob"),
                               stringsAsFactors = TRUE))
  } else {
    out <-  tmp
  }
  return(out)
}

rf_fit <- function (x, y, first, last, ...) {
  # x: The current training set of predictor data with appropriate subset
  #    of variables.
  # y: a factor vector with levels normal and nsclc.
  # first: A single logical value for whether the current predictor set has
  #        all possible variables.
  # last: Similar to first, but True when the last model is fit with the
  #       final subset size and predictors
  # ... : Optional arguments to pass to the fit function in call to rfe
  #
  # Returns a model object that can be used to make predictions
  mtry <- floor(sqrt(ncol(x)))
  rf_obj <- randomForest(x, y, importance = TRUE, 
                         mtry = mtry, keep.inbag = TRUE, ...)
  return(rf_obj)
}

rf_rank <- function (object, x, y) {
  # object: The model generated by the fit function
  # x: The current training data frame with current predictor variables
  # y: The current training outcomes (normal or nsclc)
  #
  # Returns a data frame with columns called rank_metric (MeanDecreaseAccuracy)
  # and var. Each row corresponds to a variable. Should be in descending
  # order of rank_metric (MeanDecreaseAccuracy).
  vimp <- as.data.frame(importance(object, type=1))
  vimp$var <- rownames(vimp)
  rownames(vimp) <- NULL
  colnames(vimp)[1] <- "rank_metric"
  sorted_vimp <- vimp[order(vimp$rank_metric, decreasing = TRUE), ]
  return(sorted_vimp)
}

### SVM specific ###
svm_pred <- function (object, x) {
  # object: The model generated by the fit function
  # x: The current set of predictor set for the held-back samples
  #
  # Returns a data frame with columns pred, normal, nsclc with rows
  # being the held-back samples (~70 of them in our data set). The pred
  # column contains the predictions normal or nsclc and the normal and nsclc
  # columns contains the class probabilities.
  tmp <- predict(object, x)
  if (object$modelType == "Classification" & object$control$classProbs) {
    out <- cbind(data.frame(pred = tmp),
                 as.data.frame(predict(object, x, type = "prob"),
                               stringsAsFactors = TRUE),
                 stringsAsFactors = TRUE)
  } else {
    out <-  tmp
  }
  return(out)
}

svm_fit<- function(x, y, first, last, ...) {
  # x: same as rf_fit
  # y: same as rf_fit
  # first: same as rf_fit
  # last: same as rf_fit
  # ... : Optional arguments to pass to the fit function in call to rfe
  #
  # Returns a train object. train_object$finalModel would be the model.
  train_object <- train(x, y, metric = "ROC", ...)
  return(train_object)
}

svm_rank_linear <- function(object, x, y) {
  # Same parameters as rf_rank except object is s4 object
  #
  # Returns a data frame with columns called rank_metric (which is the
  # squared w) and var.
  # Each row corresponds to a variable. Should be in descending order of
  # rank_metric (squared weight).
  w <- t(object$finalModel@coef[[1]] %*% object$finalModel@xmatrix[[1]])
  w <- w ^ 2
  vimp <- as.data.frame(w)
  colnames(vimp)[1] <- "rank_metric"
  vimp$var <- rownames(vimp)
  sorted_vimp <- vimp[order(vimp$rank_metric, decreasing = TRUE), ]
  sorted_vimp$C <- object$finalModel@param$C
  return(sorted_vimp)
}

svm_rank_rbf <- function(object, x, y) {
  # Same parameters as rf_rank except object is s4 object
  #
  # Returns a data frame with columns called rank_metric (which is the
  # change in cost function) and var. Also columns for optimal C and sigma.
  # Each row corresponds to a variable. Should be in descending order of
  # rank_metric column.
  gam <- object$bestTune$gamma
  kernel_func_denom <- 2 * (gam^2)
  
  compute_I <- function(support_vectors) {
    # Vectorized computation of the kernel matrix
    #
    # support_vectors: Matrix of support vectors (rows are support vectors)
    #
    # Returns: n x n kernel matrix, where n is the number of support vectors
    
    # Compute squared norms of each row
    sq_norms <- rowSums(support_vectors^2)
    # Compute pairwise squared distances
    pairwise_sq_dists <- outer(sq_norms, sq_norms, "+") -
      (2 * (support_vectors %*% t(support_vectors)))
    # Make potential neg distances are set to 0 in case rounding problem
    pairwise_sq_dists <- pmax(pairwise_sq_dists, 0)
    kernel_matrix <- exp(-pairwise_sq_dists / kernel_func_denom)
    return(kernel_matrix)
  }
  
  # feature vectors of support vectors
  support_vectors <- object$finalModel$SV
  I <- compute_I(support_vectors)
  
  # Compute I without each variable.
  var_imps <- sapply(1:ncol(support_vectors), function(i) {
    # Zero out the i-th feature for all support vectors
    modified_support_vectors <- support_vectors
    modified_support_vectors[, i] <- 0
    # Recompute the kernel matrix with the modified support vectors
    I_without_i <- compute_I(modified_support_vectors)
    # Compute the difference in cost function
    abs(sum(I - I_without_i))
  })
  
  # Sort variables in order of importance
  vimp <- data.frame(rank_metric = var_imps, var = colnames(support_vectors))
  sorted_vimp <- vimp[order(vimp$rank_metric, decreasing = TRUE), ]
  sorted_vimp$cost <- object$bestTune$cost
  sorted_vimp$gamma <- gam
  return(sorted_vimp)
}

### final functions ###
# RF
rf_rfe_funcs <- rfFuncs
rf_rfe_funcs$summary <- fivestats_summary
rf_rfe_funcs$selectSize <- rfe_selectSize
rf_rfe_funcs$selectVar <- rfe_selectVar
rf_rfe_funcs$pred <- rf_pred
rf_rfe_funcs$fit <- rf_fit
rf_rfe_funcs$rank <- rf_rank

# SVM
svm_rfe_funcs <- caretFuncs
svm_rfe_funcs$summary <- fivestats_summary
svm_rfe_funcs$selectSize <- rfe_selectSize
svm_rfe_funcs$selectVar <- rfe_selectVar
svm_rfe_funcs$pred <- svm_pred
svm_rfe_funcs$fit <- svm_fit
# Linear
svm_rfe_funcs_linear <- svm_rfe_funcs
svm_rfe_funcs_linear$rank <- svm_rank_linear
# RBF
svm_rfe_funcs_rbf <- svm_rfe_funcs
svm_rfe_funcs_rbf$rank <- svm_rank_rbf
